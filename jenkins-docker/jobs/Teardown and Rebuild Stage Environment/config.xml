<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@320.v5a_0933a_e7d61">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>target_stack</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>deployment_git_hash</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ROLE_ARN</name>
          <defaultValue>arn:aws:iam::${app_acct_id}:role/hms-dbmi-cnc-role</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>dataset_s3_object_key</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>destigmatized_dataset_s3_object_key</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>genomic_dataset_s3_object_key</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ami_id</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>infrastructure_git_hash</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>isDestroyOnly</name>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@5.1.0">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>${infrastructure_git_repo}</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>${infrastructure_git_hash}</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="empty-list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash
cd app-infrastructure

# Switch for environment type
if [[ &quot;${env_is_open_access,,}&quot; == &quot;true&quot; ]]; then
   rm auth-hpds-instance.tf
fi

# Terraform provider can assume role 
# Should move this to terraform once we can have multiple providers in provider.tf 
# https://registry.terraform.io/providers/hashicorp/aws/latest/docs#assuming-an-iam-role
aws sts assume-role --duration-seconds ${jenkins_provisioning_assume_role_duration} --role-arn &quot;arn:aws:iam::${cnc_acct_id}:role/system/${jenkins_s3_role_name}&quot; --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt

export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`

# Just use an s3 backend in terraform. no reason to store this state via aws cli
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate . || echo &quot;bad state or doesnt exist, it will be created&quot;

# work on eliminating these external vars
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/stack_variables.tf .
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/subnet_variables.tf .

#cp stack_variables.tf ../s3-deployment-roles/
#cp subnet_variables.tf ../s3-deployment-roles/

# why are the roles and the rest of everything for the nodes in differenet tf states?  
#aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate_roles ../s3-deployment-roles/terraform.tfstate || echo &quot;role state doesnt exist, it will be created&quot;

unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset AWS_SESSION_TOKEN

aws sts assume-role --duration-seconds ${jenkins_provisioning_assume_role_duration} --role-arn &quot;arn:aws:iam::${app_acct_id}:role/${jenkins_provisioning_assume_role_name}&quot; --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt

export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`

#  why? 
# move the roles in the app-infrastructure and have a flat(ish) model 
#cd ../s3-deployment-roles
#terraform init
#terraform destroy -auto-approve -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot; -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot; -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot;  -var=&quot;target_stack=${target_stack}&quot; -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; -var=&quot;stack_githash_long=${deployment_git_hash}&quot; || true
#terraform apply -auto-approve -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot; -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; -var=&quot;target_stack=${target_stack}&quot; -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; -var=&quot;stack_githash_long=${deployment_git_hash}&quot; || true


DOMAINS=&quot;${allowed_hosts}&quot;
# Convert commas (with optional whitespace) to spaces
DOMAINS_ARRAY=$(echo &quot;$DOMAINS&quot; | sed &apos;s/,\s*/ /g&apos;)
# Convert array of domains to regex
REGEX_DOMAINS=$(echo &quot;$DOMAINS_ARRAY&quot; | sed &apos;s/ /|/g&apos;)

terraform init 
if $isDestroyOnly; then

  terraform destroy -auto-approve \
     -var=&quot;ami-id=${ami_id}&quot; \
     -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
     -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
     -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
     -var=&quot;target_stack=${target_stack}&quot; \
     -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
     -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
     -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
     -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
     -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
     -var=&quot;dsm_url=${dsm_url}&quot; \
     -var=&quot;allowed_hosts=${REGEX_DOMAINS}&quot; \
     -var=&quot;trendmicro_dsa_cidr_blocks=${trendmicro_dsa_cidr_blocks}&quot; || true
     
  unset AWS_ACCESS_KEY_ID
  unset AWS_SECRET_ACCESS_KEY
  unset AWS_SESSION_TOKEN
  
  aws sts assume-role --duration-seconds ${jenkins_provisioning_assume_role_duration} --role-arn &quot;arn:aws:iam::${cnc_acct_id}:role/system/${jenkins_s3_role_name}&quot; --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt
  
  export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
  export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
  export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
  
  # Move to terraform backend
  aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate

else
  terraform destroy -auto-approve \
     -var=&quot;ami-id=${ami_id}&quot; \
     -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
     -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
     -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
     -var=&quot;target_stack=${target_stack}&quot; \
     -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
     -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
     -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
     -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
     -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
     -var=&quot;dsm_url=${dsm_url}&quot; \
     -var=&quot;allowed_hosts=${REGEX_DOMAINS}&quot; \
     -var=&quot;trendmicro_dsa_cidr_blocks=${trendmicro_dsa_cidr_blocks}&quot; || true

  terraform apply -auto-approve \
     -var=&quot;ami-id=${ami_id}&quot; \
     -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
     -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
     -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
     -var=&quot;target_stack=${target_stack}&quot; \
     -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
     -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
     -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
     -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
     -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
     -var=&quot;dsm_url=${dsm_url}&quot; \
     -var=&quot;allowed_hosts=${REGEX_DOMAINS}&quot; \
     -var=&quot;trendmicro_dsa_cidr_blocks=${trendmicro_dsa_cidr_blocks}&quot; || true


  unset AWS_ACCESS_KEY_ID
  unset AWS_SECRET_ACCESS_KEY
  unset AWS_SESSION_TOKEN
  
  aws sts assume-role --duration-seconds ${jenkins_provisioning_assume_role_duration} --role-arn &quot;arn:aws:iam::${cnc_acct_id}:role/system/${jenkins_s3_role_name}&quot; --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt
  
  export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
  export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
  export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
  
  # Move to terraform backend
  # If script fails before state file is uploaded to s3 state will be lost for created objects \
  # terraform destroy will not destroy anything as it points to old state and apply will fail as objects may already exist
  # Will have to manually destroy and delete roles, ec2s, etc. in that scenario
  aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate
  # roles are now in the same state as their related resources..
  #aws s3 cp ../s3-deployment-roles/terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate_roles
  
  # These files are uploaded to s3 because user-scripts download them.  The user scripts are already running 
  # so this is a race condition at this point as terraform has been applied
  #  have terraform provision these to the ec2 and remove the aws cli stuff from the user-scripts and here
  aws s3 --sse=AES256 cp picsureui-settings.json s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/picsureui_settings.json
  aws s3 --sse=AES256 cp standalone.xml s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/standalone.xml
  aws s3 --sse=AES256 cp pic-sure-schema.sql s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/pic-sure-schema.sql
  aws s3 --sse=AES256 cp httpd-vhosts.conf s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/httpd-vhosts.conf
  aws s3 --sse=AES256 cp aggregate-resource.properties s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/aggregate-resource.properties
  aws s3 --sse=AES256 cp visualization-resource.properties s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/visualization-resource.properties
  
  unset AWS_ACCESS_KEY_ID
  unset AWS_SECRET_ACCESS_KEY
  unset AWS_SESSION_TOKEN
  
fi</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.45">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>