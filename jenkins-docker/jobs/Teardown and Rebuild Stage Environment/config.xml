<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <jenkins.model.BuildDiscarderProperty>
      <strategy class="hudson.tasks.LogRotator">
        <daysToKeep>-1</daysToKeep>
        <numToKeep>10</numToKeep>
        <artifactDaysToKeep>-1</artifactDaysToKeep>
        <artifactNumToKeep>-1</artifactNumToKeep>
      </strategy>
    </jenkins.model.BuildDiscarderProperty>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@1.34">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>target_stack</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>deployment_git_hash</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ROLE_ARN</name>
          <defaultValue>$arn_role_app</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>dataset_s3_object_key</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>destigmatized_dataset_s3_object_key</name>
          <description>points to the rekeyed javabins that have been stripped of stigmatizing variables</description>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>genomic_dataset_s3_object_key</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ami_id</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>infrastructure_git_hash</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>source_dictionary_s3_object_key</name>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@4.10.3">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>https://github.com/hms-dbmi/avillachlab-secure-infrastructure</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>${infrastructure_git_hash}</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="empty-list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>cd app-infrastructure
wget https://releases.hashicorp.com/terraform/0.12.31/terraform_0.12.31_linux_amd64.zip &amp;&amp; unzip terraform_0.12.31_linux_amd64.zip &amp;&amp; mv terraform /usr/local/bin/

aws sts assume-role --duration-seconds 900 --role-arn $arn_role_cnc --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt

export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`

aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate .
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/stack_variables.tf .
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/subnet_variables.tf .
cp stack_variables.tf ../s3-deployment-roles/
cp subnet_variables.tf ../s3-deployment-roles/
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate_roles ../s3-deployment-roles/terraform.tfstate || echo &quot;role state doesnt exist, it will be created&quot;

unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset AWS_SESSION_TOKEN

aws sts assume-role --duration-seconds 900 --role-arn $arn_role_app --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt

export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`

cd ../s3-deployment-roles
terraform init
terraform destroy -auto-approve -var=&quot;source_dictionary_s3_object_key=${source_dictionary_s3_object_key}&quot; -var=&quot;dataset-s3-object-key=${dataset_s3_object_key}&quot; -var=&quot;destigmatized-dataset-s3-object-key=${destigmatized_dataset_s3_object_key}&quot; -var=&quot;genomic-dataset-s3-object-key=${genomic_dataset_s3_object_key}&quot;  -var=&quot;target-stack=${target_stack}&quot; -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; -var=&quot;stack_githash_long=${deployment_git_hash}&quot; || true
terraform apply -auto-approve -var=&quot;source_dictionary_s3_object_key=${source_dictionary_s3_object_key}&quot; -var=&quot;dataset-s3-object-key=${dataset_s3_object_key}&quot;  -var=&quot;destigmatized-dataset-s3-object-key=${destigmatized_dataset_s3_object_key}&quot; -var=&quot;genomic-dataset-s3-object-key=${genomic_dataset_s3_object_key}&quot; -var=&quot;target-stack=${target_stack}&quot; -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; -var=&quot;stack_githash_long=${deployment_git_hash}&quot; || true

DOMAINS=&quot;${allowed_hosts}&quot;
# Convert commas (with optional whitespace) to spaces
DOMAINS_ARRAY=$(echo &quot;$DOMAINS&quot; | sed &apos;s/,\s*/ /g&apos;)
# Convert array of domains to regex
REGEX_DOMAINS=$(echo &quot;$DOMAINS_ARRAY&quot; | sed &apos;s/ /|/g&apos;)

cd ../app-infrastructure
terraform init
terraform destroy -auto-approve -var=&quot;source_dictionary_s3_object_key=${source_dictionary_s3_object_key}&quot; -var=&quot;ami-id=${ami_id}&quot; -var=&quot;dataset-s3-object-key=${dataset_s3_object_key}&quot;  -var=&quot;destigmatized-dataset-s3-object-key=${destigmatized_dataset_s3_object_key}&quot; -var=&quot;genomic-dataset-s3-object-key=${genomic_dataset_s3_object_key}&quot; -var=&quot;target-stack=${target_stack}&quot; -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; -var=&quot;stack_githash_long=${deployment_git_hash}&quot; -var=&quot;allowed_hosts=${REGEX_DOMAINS}&quot; || true
terraform apply -auto-approve -var=&quot;source_dictionary_s3_object_key=${source_dictionary_s3_object_key}&quot; -var=&quot;ami-id=${ami_id}&quot; -var=&quot;dataset-s3-object-key=${dataset_s3_object_key}&quot;  -var=&quot;destigmatized-dataset-s3-object-key=${destigmatized_dataset_s3_object_key}&quot; -var=&quot;genomic-dataset-s3-object-key=${genomic_dataset_s3_object_key}&quot; -var=&quot;target-stack=${target_stack}&quot; -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; -var=&quot;stack_githash_long=${deployment_git_hash}&quot; -var=&quot;allowed_hosts=${REGEX_DOMAINS}&quot; || true

echo &quot;
{
  \&quot;Changes\&quot;: [
    {
      \&quot;Action\&quot;: \&quot;UPSERT\&quot;,
      \&quot;ResourceRecordSet\&quot;: {
        \&quot;Name\&quot;: \&quot;httpd.${target_stack}.datastage.hms.harvard.edu\&quot;,
        \&quot;Type\&quot;: \&quot;A\&quot;,
        \&quot;TTL\&quot;: 60,
        \&quot;ResourceRecords\&quot;: [
          {
            \&quot;Value\&quot;: \&quot;$(grep httpd-ec2-private_ip ip-vars.properties | cut -d &quot;=&quot; -f 2)\&quot;
          }
        ]
      }
    },{
      \&quot;Action\&quot;: \&quot;UPSERT\&quot;,
      \&quot;ResourceRecordSet\&quot;: {
        \&quot;Name\&quot;: \&quot;wildfly.${target_stack}.datastage.hms.harvard.edu\&quot;,
        \&quot;Type\&quot;: \&quot;A\&quot;,
        \&quot;TTL\&quot;: 60,
        \&quot;ResourceRecords\&quot;: [
          {
            \&quot;Value\&quot;: \&quot;$(grep wildfly-ec2-private_ip ip-vars.properties | cut -d &quot;=&quot; -f 2)\&quot;
          }
        ]
      }
    },{
      \&quot;Action\&quot;: \&quot;UPSERT\&quot;,
      \&quot;ResourceRecordSet\&quot;: {
        \&quot;Name\&quot;: \&quot;open-hpds.${target_stack}.datastage.hms.harvard.edu\&quot;,
        \&quot;Type\&quot;: \&quot;A\&quot;,
        \&quot;TTL\&quot;: 60,
        \&quot;ResourceRecords\&quot;: [
          {
            \&quot;Value\&quot;: \&quot;$(grep open-hpds-ec2-private_ip ip-vars.properties | cut -d &quot;=&quot; -f 2)\&quot;
          }
        ]
      }
    },{
      \&quot;Action\&quot;: \&quot;UPSERT\&quot;,
      \&quot;ResourceRecordSet\&quot;: {
        \&quot;Name\&quot;: \&quot;auth-hpds.${target_stack}.datastage.hms.harvard.edu\&quot;,
        \&quot;Type\&quot;: \&quot;A\&quot;,
        \&quot;TTL\&quot;: 60,
        \&quot;ResourceRecords\&quot;: [
          {
            \&quot;Value\&quot;: \&quot;$(grep auth-hpds-ec2-private_ip ip-vars.properties | cut -d &quot;=&quot; -f 2)\&quot;
          }
        ]
      }
    },{
      \&quot;Action\&quot;: \&quot;UPSERT\&quot;,
      \&quot;ResourceRecordSet\&quot;: {
        \&quot;Name\&quot;: \&quot;dictionary.${target_stack}.datastage.hms.harvard.edu\&quot;,
        \&quot;Type\&quot;: \&quot;A\&quot;,
        \&quot;TTL\&quot;: 60,
        \&quot;ResourceRecords\&quot;: [
          {
            \&quot;Value\&quot;: \&quot;$(grep dictionary-ec2-private_ip ip-vars.properties | cut -d &quot;=&quot; -f 2)\&quot;
          }
        ]
      }
    },{
      \&quot;Action\&quot;: \&quot;UPSERT\&quot;,
      \&quot;ResourceRecordSet\&quot;: {
        \&quot;Name\&quot;: \&quot;picsure-db.${target_stack}.datastage.hms.harvard.edu\&quot;,
        \&quot;Type\&quot;: \&quot;CNAME\&quot;,
        \&quot;TTL\&quot;: 60,
        \&quot;ResourceRecords\&quot;: [
          {
            \&quot;Value\&quot;: \&quot;$(grep pic-sure-mysql-address ip-vars.properties | cut -d &quot;=&quot; -f 2)\&quot;
          }
        ]
      }
    }
  ]
}


&quot; &gt; route-53-records.json
aws route53 change-resource-record-sets --hosted-zone-id $(grep -A4 &apos;variable &quot;internal-dns-zone-id&apos; subnet_variables.tf  |  grep default | cut -d &quot;\&quot;&quot; -f 2) --change-batch file://route-53-records.json || true

unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset AWS_SESSION_TOKEN

aws sts assume-role --duration-seconds 900 --role-arn $arn_role_cnc --role-session-name &quot;teardown-rebuild&quot; &gt; assume-role-output.txt

export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`

aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate 
aws s3 cp ../s3-deployment-roles/terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${target_stack}/terraform.tfstate_roles


aws s3 --sse=AES256 cp picsureui-settings.json s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/picsureui_settings.json
#aws s3 --sse=AES256 cp psamaui-settings.json s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/psamaui_settings.json
aws s3 --sse=AES256 cp standalone.xml s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/standalone.xml
aws s3 --sse=AES256 cp pic-sure-schema.sql s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/pic-sure-schema.sql
aws s3 --sse=AES256 cp httpd-vhosts.conf s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/httpd-vhosts.conf
aws s3 --sse=AES256 cp aggregate-resource.properties s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/aggregate-resource.properties
aws s3 --sse=AES256 cp visualization-resource.properties s3://$stack_s3_bucket/configs/jenkins_pipeline_build_${deployment_git_hash}/visualization-resource.properties



unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset AWS_SESSION_TOKEN
</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.40">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>