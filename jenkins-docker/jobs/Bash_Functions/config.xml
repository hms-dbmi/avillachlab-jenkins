<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description>Job will be triggered by Check for updates. &#xd;
&#xd;
Gives a central location to store bash functions used in the pipeline.</description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>echo &apos;
assume_role(){
  local role_arn=${1:-&quot;arn:aws:iam::&apos;${app_acct_id}&apos;:role/&apos;${jenkins_provisioning_assume_role_name}&apos;&quot;}
  OUTPUT=$(aws sts assume-role \
      --role-arn $role_arn \
      --role-session-name &quot;teardown-rebuild&quot; \
      --query &quot;Credentials.[AccessKeyId,SecretAccessKey,SessionToken]&quot; \
      --output text)

  export AWS_ACCESS_KEY_ID=$(echo $OUTPUT | awk &quot;{print \$1}&quot;)
  export AWS_SECRET_ACCESS_KEY=$(echo $OUTPUT | awk &quot;{print \$2}&quot;)
  export AWS_SESSION_TOKEN=$(echo $OUTPUT | awk &quot;{print \$3}&quot;)
  export AWS_DEFAULT_REGION=us-east-1
}

reset_role(){
  unset AWS_ACCESS_KEY_ID
  unset AWS_SECRET_ACCESS_KEY
  unset AWS_SESSION_TOKEN
}

export -f assume_role
export -f reset_role
        &apos; &gt; role_functions.sh</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command># Provides automation for swapping instances between staging and live target groups, using green/blue deployment strategy.

# Script Usage:
# To use this script, specify the names of the staging and live target groups, as well as JSON files
# containing tag filters for identifying instances to swap between the target groups.

# Example Usage:
# swap_stacks &quot;staging-tg-name&quot; &quot;live-tg-name&quot; &quot;staging-httpd-tags.txt&quot; &quot;live-httpd-tags.txt&quot;

# Function to get Target Group ARN by name

echo &apos;
get_target_group_arn_by_name() {
  # Use AWS CLI to describe target groups and extract the ARN by name
  aws elbv2 describe-target-groups \
    --query &quot;TargetGroups[?TargetGroupName==\`$1\`].TargetGroupArn&quot; \
    --output text
}

# Function to get Target Group VPC by name
get_target_group_vpc_by_tg_name() {
  local target_group_name=$1
  # Use AWS CLI to describe the target group and extract the VPC ID
  aws elbv2 describe-target-groups \
    --names &quot;$target_group_name&quot; \
    --query &quot;TargetGroups[0].VpcId&quot; \
    --output text
}

# Function to get private IP by tags
get_private_ip_by_tags() {
  local tag_filters_file=&quot;$1&quot;
  # Use AWS CLI to describe instances with specified tag filters from a file and extract private IPs
  aws ec2 describe-instances \
    --filters &quot;file://$tag_filters_file&quot; \
    --query &quot;Reservations[].Instances[].PrivateIpAddress&quot; \
    --output text
}

# Function to check if an EC2 instance is in the same VPC as a target group
is_ec2_in_same_vpc_as_target_group() {
  local ec2_private_ip=&quot;$1&quot;
  local target_group_vpc_id=&quot;$2&quot;
  # Use AWS CLI to describe the EC2 instance and extract its VPC ID
  local ec2_vpc_id=$(aws ec2 describe-instances \
    --filters &quot;Name=private-ip-address,Values=$ec2_private_ip&quot; \
    --query &quot;Reservations[0].Instances[0].VpcId&quot; \
    --output text)

  # Compare the EC2 instances VPC ID with the known target groups VPC ID
  if [ &quot;$ec2_vpc_id&quot; == &quot;$target_group_vpc_id&quot; ]; then
    echo &quot;The EC2 instance with private IP $ec2_private_ip is in the same VPC as the target group.&quot;
    return 0  # Return success (0)
  else
    echo &quot;The EC2 instance with private IP $ec2_private_ip is NOT in the same VPC as the target group.&quot;
    return 1  # Return failure (non-zero)
  fi
}

# Function to register targets in a target group
register_targets() {
  local local_target_group_vpc=&quot;$1&quot;
  local local_target_group_arn=&quot;$2&quot;
  local httpd_priv_ips=(&quot;${@:3}&quot;)

  for local_httpd_priv_ips in &quot;${httpd_priv_ips[@]}&quot;; do
    # Check if the EC2 instance is in the same VPC as the target group and register it accordingly
    if is_ec2_in_same_vpc_as_target_group &quot;$local_httpd_priv_ips&quot; &quot;$local_target_group_vpc&quot;; then
      aws elbv2 register-targets --target-group-arn $local_target_group_arn --targets &quot;Id=$local_httpd_priv_ips&quot;
    else
      aws elbv2 register-targets --target-group-arn $local_target_group_arn --targets &quot;Id=$local_httpd_priv_ips,AvailabilityZone=all&quot;
    fi
  done
}

# Function to deregister targets from a target group
deregister_targets() {
  local local_target_group_vpc=&quot;$1&quot;
  local local_target_group_arn=&quot;$2&quot;
  local httpd_priv_ips=(&quot;${@:3}&quot;)

  for httpd_priv_ip in &quot;${httpd_priv_ips[@]}&quot;; do
    # Check if the EC2 instance is in the same VPC as the target group and deregister it accordingly
    if is_ec2_in_same_vpc_as_target_group &quot;$httpd_priv_ip&quot; &quot;$local_target_group_vpc&quot;; then
      aws elbv2 deregister-targets --target-group-arn $local_target_group_arn --targets &quot;Id=$httpd_priv_ip&quot;
    else
      aws elbv2 deregister-targets --target-group-arn $local_target_group_arn --targets &quot;Id=$httpd_priv_ip,AvailabilityZone=all&quot;
    fi
  done
}

# Function to wait for a target group to become healthy for all instances
wait_for_target_group_health() {
  local target_group_arn=&quot;$1&quot;
  local wait_for_health=&quot;$2&quot;
  local target_instance_ips=(&quot;${@:3}&quot;)

  local timeout_secs=600
  local start_time=$(date +%s)

  for target_instance_ip in &quot;${target_instance_ips[@]}&quot;; do
    local health_status=$(aws elbv2 describe-target-health \
      --target-group-arn &quot;$target_group_arn&quot; \
      --targets &quot;Id=$target_instance_ip&quot; \
      --query &quot;TargetHealthDescriptions[0].TargetHealth.State&quot; \
      --output text
    )

    while [[ ${health_status^^} != ${wait_for_health^^} ]]; do
      local elapsed_time=$(( $(date +%s) - start_time ))
      if [ $elapsed_time -ge $timeout_secs ]; then
        echo &quot;Target group health check exceeds timeout&quot;
        echo &quot;Target=$target_instance_ip Current_Health=${health_status^^} wait_for_health=$wait_for_health&quot;
        exit 1
      fi

      # Use AWS CLI to describe the target health status and update the health_status variable
      health_status=$(aws elbv2 describe-target-health \
        --target-group-arn &quot;$target_group_arn&quot; \
        --targets &quot;Id=$target_instance_ip&quot; \
        --query &quot;TargetHealthDescriptions[0].TargetHealth.State&quot; \
        --output text
      )
      echo &quot;$target_instance_ip - ${health_status^^}.  Waiting for health of ${wait_for_health^^}&quot;
      sleep 10  # Wait for 10 seconds before checking again
    done
  done
}

# Function to swap instances between staging and live target groups
swap_stacks() {
  local staging_tg_name=$1
  local live_tg_name=$2
  local staging_httpd_tags_file=&quot;$3&quot;
  local live_httpd_tags_file=&quot;$4&quot;
  local fail_empty_stacks=&quot;${5,,:-&quot;false&quot;,,}&quot;  # Set to true for stable prod and release testing
  echo &quot;staging_tg_name=$1&quot;
  echo &quot;live_tg_name=$2&quot;
  echo &quot;staging_httpd_tags_file=$3&quot;
  echo &quot;live_httpd_tags_file=$4&quot;

  # Get Target Group ARNs using the function
  local local_staging_target_group_arn=$(get_target_group_arn_by_name &quot;$staging_tg_name&quot;)
  local local_live_target_group_arn=$(get_target_group_arn_by_name &quot;$live_tg_name&quot;)

  # Get target group VPC. Both target groups are known to be in the same VPC
  local local_target_group_vpc=$(get_target_group_vpc_by_tg_name &quot;$live_tg_name&quot;)

  # Get private IPs using the function with tags from files
  local local_staging_httpd_instance_prv_ips=($(get_private_ip_by_tags &quot;$staging_httpd_tags_file&quot;))
  local local_live_httpd_instance_prv_ips=($(get_private_ip_by_tags &quot;$live_httpd_tags_file&quot;))

  # Promote Staging to Live (green to blue)
  echo &quot;Promote Staging to Live (green to blue)&quot;
  if [ -z &quot;${local_staging_httpd_instance_prv_ips}&quot; ]; then
    echo &quot;No staging IP Addresses found when promoting to live server.&quot;
    echo &quot;Ensure nodes have been created with proper tags for Node, Project, and Stack keys.&quot;
    if [ &quot;${fail_empty_stacks}&quot; = &quot;true&quot; ]; then
      echo &quot;failing build&quot;
      exit 1
    fi
  else
    register_targets &quot;$local_target_group_vpc&quot; &quot;$local_live_target_group_arn&quot; &quot;${local_staging_httpd_instance_prv_ips[@]}&quot;
    wait_for_target_group_health &quot;$local_live_target_group_arn&quot; &quot;HEALTHY&quot; &quot;${local_staging_httpd_instance_prv_ips[@]}&quot;
  fi

  # Demote Live to Staging (blue to green)
  echo &quot;Demote Live to Staging (blue to green)&quot;
  if [ -z &quot;${local_live_httpd_instance_prv_ips}&quot; ]; then
    echo &quot;No live IP Addresses found when demoting to staging server.&quot;
    echo &quot;Ensure nodes have been created with proper tags for Node, Project, and Stack keys.&quot;
    if [ &quot;${fail_empty_stacks}&quot; = &quot;true&quot; ]; then
      echo &quot;failing build&quot;
      exit 1
    fi
  else
    register_targets &quot;$local_target_group_vpc&quot; &quot;$local_staging_target_group_arn&quot; &quot;${local_live_httpd_instance_prv_ips[@]}&quot;
    wait_for_target_group_health &quot;$local_staging_target_group_arn&quot; &quot;HEALTHY&quot; &quot;${local_live_httpd_instance_prv_ips[@]}&quot;
  fi

  # Deregister previous Live from Live TG (remove blue from blue)
  echo &quot;Deregister previous Live from Live TG (remove blue from blue)&quot;
  if [ -z &quot;${local_live_httpd_instance_prv_ips}&quot; ]; then
    echo &quot;No live IP Addresses found when deregistering from live TG.&quot;
    echo &quot;Ensure nodes have been created with proper tags for Node, Project, and Stack keys and that it has a TGA.&quot;
    if [ &quot;${fail_empty_stacks}&quot; = &quot;true&quot; ]; then
      echo &quot;failing build&quot;
      exit 1
    fi
  else
    deregister_targets &quot;$local_target_group_vpc&quot; &quot;$local_live_target_group_arn&quot; &quot;${local_live_httpd_instance_prv_ips[@]}&quot;
    # Wait for draining
    wait_for_target_group_health &quot;$local_live_target_group_arn&quot; &quot;UNUSED&quot; &quot;${local_live_httpd_instance_prv_ips[@]}&quot;
  fi

  # Deregister previous Staging from Staging TG (remove green from green)
  echo &quot;Deregister previous Staging from Staging TG (remove green from green)&quot;
  if [ -z &quot;${local_staging_httpd_instance_prv_ips}&quot; ]; then
    echo &quot;No staging IP Addresses found when deregistering from live TG.&quot;
    echo &quot;Ensure nodes have been created with proper tags for Node, Project, and Stack keys and that it has a TGA.&quot;
    if [ &quot;${fail_empty_stacks}&quot; = &quot;true&quot; ]; then
      echo &quot;failing build&quot;
      exit 1
    fi
  else
    deregister_targets &quot;$local_target_group_vpc&quot; &quot;$local_staging_target_group_arn&quot; &quot;${local_staging_httpd_instance_prv_ips[@]}&quot;
    # Wait for draining
    wait_for_target_group_health &quot;$local_staging_target_group_arn&quot; &quot;UNUSED&quot; &quot;${local_staging_httpd_instance_prv_ips[@]}&quot;
  fi
  echo &quot;Swap Stacks complete&quot;
}&apos; &gt; target_group_attachment_functions.sh</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command>cat &lt;&lt;&apos;EOF&apos; &gt; pic_sure_rds_snapshot.sh
# Funtion to return latest snapshot for rds instance
get_latest_rds_snapshot_id() {
  local picsure_rds_strategy=&quot;$1&quot;
  local stack=&quot;$2&quot;
  local project=&quot;$3&quot;

  if [ &quot;${picsure_rds_strategy}&quot; == &quot;MANAGED_USE_LATEST_SS&quot; ]; then
    db_instance_identifier=$(get_db_instance_identifier_by_tag &quot;$live_stack&quot; &quot;$env_project&quot;)
    latest_snapshot=$(aws rds describe-db-snapshots \
      --db-instance-identifier &quot;$db_instance_identifier&quot; \
      --query &quot;DBSnapshots | sort_by(@, &amp;SnapshotCreateTime) | [-1].DBSnapshotIdentifier&quot; \
      --output text)
  fi
  echo &quot;$latest_snapshot&quot;
}

# find db instance by stack and project tags
get_db_instance_identifier_by_tag() {
  local stack=&quot;$1&quot;
  local project=&quot;$2&quot;
  local identifier
  identifier=$(aws rds describe-db-instances | jq --arg stack &quot;$stack&quot; --arg project &quot;$project&quot; -r &apos;.DBInstances[] | select(.TagList[] | .Key == &quot;Stack&quot; and .Value == $stack) | select(.TagList[] | .Key == &quot;Project&quot; and .Value == $project) | .DBInstanceIdentifier&apos;)
  echo &quot;$identifier&quot;
}

create_rds_snapshot_by_tag() {
  local live_stack=&quot;$1&quot;
  local env_project=&quot;$2&quot;

  # Find the RDS instance based on the specified tag
  local db_instance_identifier
  db_instance_identifier=$(get_db_instance_identifier_by_tag &quot;$live_stack&quot; &quot;$env_project&quot;)

  if [ -z &quot;$db_instance_identifier&quot; ]; then
    echo &quot;No RDS instance found with tag: $live_stack and $env_project&quot;
    return 1
  fi
  local timestamp=$(date +&quot;%Y-%m-%d-%H-%M-%S&quot;)
  local snapshot_identifier=&quot;${db_instance_identifier}-snapshot-${timestamp}&quot;

  # Create a snapshot for the RDS instance
  aws rds create-db-snapshot \
    --db-instance-identifier &quot;$db_instance_identifier&quot; \
    --db-snapshot-identifier &quot;$snapshot_identifier&quot;

  while true; do
    local status=$(aws rds describe-db-snapshots \
      --db-instance-identifier &quot;$db_instance_identifier&quot; \
      --db-snapshot-identifier &quot;$snapshot_identifier&quot; \
      --query &quot;DBSnapshots[0].Status&quot; --output text)

    if [ &quot;${status,,}&quot; = &quot;available&quot; ]; then
      echo &quot;$snapshot_identifier&quot;
      return 0
    else
      sleep 20
    fi
  done
}

# Function to wait for an RDS instance to become available and then create a snapshot
create_snapshot_when_available() {
    local DB_INSTANCE_IDENTIFIER=$1
    local SNAPSHOT_IDENTIFIER=&quot;${DB_INSTANCE_IDENTIFIER}-snapshot-$(date +%Y%m%d-%H%M%S)&quot;

    while true; do
        status=$(aws rds describe-db-instances --db-instance-identifier &quot;${DB_INSTANCE_IDENTIFIER}&quot; --query &apos;DBInstances[*].DBInstanceStatus&apos; --output text)
        echo &quot;Current status: $status&quot;
        if [ &quot;$status&quot; == &quot;available&quot; ]; then
            echo &quot;Instance is available. Creating snapshot...&quot;
            aws rds create-db-snapshot --db-instance-identifier &quot;${DB_INSTANCE_IDENTIFIER}&quot; --db-snapshot-identifier &quot;${SNAPSHOT_IDENTIFIER}&quot;
            echo &quot;Snapshot ${SNAPSHOT_IDENTIFIER} creation initiated.&quot;
            break
        else
            echo &quot;Waiting for instance ${DB_INSTANCE_IDENTIFIER} to become available...&quot;
            sleep 30
        fi
    done
}

# Function to retrieve the most recent snapshot identifier for a specified RDS instance
get_latest_snapshot_identifier() {
    local DB_INSTANCE_IDENTIFIER=$1
   	local output=$(aws rds describe-db-snapshots \
    --db-instance-identifier &quot;${DB_INSTANCE_IDENTIFIER}&quot; \
    --query &apos;DBSnapshots[?SnapshotType==`manual`].[DBSnapshotIdentifier,SnapshotCreateTime] | sort_by(@, &amp;[1]) | [-1]&apos; \
    --output text)

    local snapshot_identifier=$(echo $output | awk &apos;{print $1}&apos;)
    echo &quot;The latest snapshot identifier for ${DB_INSTANCE_IDENTIFIER} is: $snapshot_identifier&quot;
    # Optionally, you can return the identifier if you need to use it in another context
    echo $snapshot_identifier
}

# Function to keep only the latest 3 manually created RDS snapshots and delete the rest
manage_rds_snapshots() {
  local db_instance_identifier=&quot;$1&quot;

  # Get the list of manually created snapshot identifiers sorted by creation time in descending order
  # Filters out automated snapshots and assumes snapshot names contain the creation date in a sortable format
  local snapshots_to_delete=$(aws rds describe-db-snapshots --db-instance-identifier &quot;$db_instance_identifier&quot; \
                               --query &apos;DBSnapshots[?SnapshotType==`manual`].[DBSnapshotIdentifier,SnapshotCreateTime]&apos; \
                               --output text | sort -k2,2r | awk &apos;NR&gt;3 {print $1}&apos;)

  # Loop through and delete snapshots older than the 3 most recent manually created ones
  for snapshot_id in $snapshots_to_delete; do
    echo &quot;Deleting snapshot: $snapshot_id&quot;
    aws rds delete-db-snapshot --db-snapshot-identifier &quot;$snapshot_id&quot;
    # Consider adding error handling here to check the success of the deletion
  done
}
EOF
</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command>cat &lt;&lt;&apos;EOF&apos; &gt; jwt_token.sh
# Function to extract and return the expiration date of the JWT token
get_jwt_expiration_date() {
    local token=&quot;$1&quot;
    local payload

    # Decode payload
    payload=$(echo &quot;$token&quot; | cut -d&quot;.&quot; -f2 | tr &apos;_-&apos; &apos;/+&apos; | tr -d &apos;=&apos; | base64 -d 2&gt;/dev/null)
    # Extract and convert exp field to readable date
    local exp=$(echo &quot;$payload&quot; | jq &apos;.exp&apos; | tr -d &apos;&quot;&apos;)
    local exp_date=$(date -d &quot;@$exp&quot; 2&gt;/dev/null)

    echo &quot;$exp_date&quot;
}

# Function to check if the token is expiring within the next 30 days
is_expiring_soon() {
    local exp_date=&quot;$1&quot;
    local exp_date_in_seconds=$(date -d &quot;$exp_date&quot; +%s)
    local current_date_plus_30=$(date -d &quot;+30 days&quot; +%s)

    if [ &quot;$exp_date_in_seconds&quot; -le &quot;$current_date_plus_30&quot; ]; then
        return 0 # Token is expiring soon
    else
        return 1 # Token is not expiring soon
    fi
}

# Create JWT token
# Clones a Git repository, generates a valid token, and exports it to an environment variable
# Parameters:
#   $1: Path to the secrets file
#   $2: Git repository URL for jwt-creator
#   $3: Token subject
#   $4: Token duration (integer)
#   $5: Token duration unit (default is &quot;day&quot;)
create_jwt_token() {
  local secret=&quot;${1}&quot;
  local jwt_creator_repo=&quot;${2}&quot;
  local subject=${3}
  local duration_int=${4}
  local duration_unit=${5:-day}

  # Clone the Git repository
  git clone &quot;${jwt_creator_repo}&quot; jwt_creator || { echo &quot;Failed to clone repository&quot;; exit 1; }

  # Change to the cloned directory
  cd jwt_creator
  mvn clean install || { echo &quot;Maven build failed&quot;; exit 1; }

  cd target || { echo &quot;Target directory not found&quot;; exit 1; }
  echo &quot;$secret&quot; &gt; secrets.txt

  # Assuming generateJwt.jar is built and exists
  export CREATE_JWT_TOKEN_OUTPUT=$(java -jar generateJwt.jar &quot;secrets.txt&quot; sub &quot;$subject&quot; &quot;$duration_int&quot; &quot;$duration_unit&quot; | grep -v &quot;Generating&quot;)

  # Cleanup
  cd &quot;${WORKSPACE}&quot;
}
EOF</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command>cat &lt;&lt;&apos;EOF&apos; &gt; secret_functions.sh
### Bash functions that need to be migrated to the Bash_Functions job
# Function to fetch a secret from AWS Secrets Manager
fetch_secret() {
    local secret_id=$1
    aws secretsmanager get-secret-value --secret-id &quot;$secret_id&quot;
}

# Function to extract a specific field from a secret
extract_field() {
    local secret=$1
    local field=$2
    echo &quot;$secret&quot; | jq -r .SecretString | jq -r .$field
}
EOF</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command>cat &lt;&lt;&apos;EOF&apos; &gt; database_migration_functions.sh
create_flyway_conf() {
  # Parameters:
  # $1 = Database Name
  # $2 = RDS_ENDPOINT
  # $3 = DATABASE_USER
  # $4 = DATABASE_PASSWORD
  # $5 = Placeholders as a string &quot;key1=value1,key2=value2&quot;

  # Define the file path dynamically based on the database name
  CONF_FILE=&quot;conf/$1_flyway.conf&quot;

  # Ensure the conf directory exists
  mkdir -p conf

  # Create or overwrite the flyway.conf file with the new content
  echo &quot;flyway.url=jdbc:mysql://$2/$1&quot; &gt; $CONF_FILE
  echo &quot;flyway.user=$3&quot; &gt;&gt; $CONF_FILE
  echo &quot;flyway.password=$4&quot; &gt;&gt; $CONF_FILE
  echo &quot;flyway.locations=filesystem:/flyway/sql&quot; &gt;&gt; $CONF_FILE
  echo &quot;flyway.baselineVersion=0&quot; &gt;&gt; $CONF_FILE  # Setting the baseline version to 0
  echo &quot;flyway.baselineOnMigrate=true&quot; &gt;&gt; $CONF_FILE  # Automatically baseline at the first migration (V0)

  # Process placeholders if provided
  if [[ -n &quot;$5&quot; ]]; then
    # Split the placeholder string into an array
    IFS=&apos;,&apos; read -r -a placeholders &lt;&lt;&lt; &quot;$5&quot;
    for placeholder in &quot;${placeholders[@]}&quot;; do
      # Each placeholder is in the form key=value
      echo &quot;flyway.placeholders.${placeholder}&quot; &gt;&gt; $CONF_FILE
    done
  fi

  echo &quot;Created or updated $CONF_FILE successfully.&quot;
}


run_flyway_migration() {
  local sql_path=$1
  local flyway_conf_path=$2

  docker run --rm --network=host \
    -v &quot;$(pwd)/${sql_path}:/flyway/sql&quot; \
    -v &quot;$(pwd)/${flyway_conf_path}:/flyway/conf/flyway.conf&quot; \
    flyway/flyway:10.8 -configFiles=/flyway/conf/flyway.conf -X migrate

  # Capture the exit status of the docker command
  local status=$?

  # Check if the status is not zero (which indicates an error)
  if [ $status -ne 0 ]; then
    echo &quot;Error: Flyway migration failed with status $status&quot;
    exit $status  # Exit the script with the same status, causing the Jenkins job to fail
  fi
}
EOF</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command>cat &lt;&lt;&apos;EOF&apos; &gt; database_functions.sh
# Global variables for shared database configuration
RDS_ENDPOINT=&quot;&quot;
DATABASE_USER=&quot;&quot;
DATABASE_PASSWORD=&quot;&quot;
MYSQL_IMAGE=&quot;mysql:8.0.35&quot;

# Function to initialize shared database configuration
initialize_shared_db_config() {
    RDS_ENDPOINT=$1
    DATABASE_USER=$2
    DATABASE_PASSWORD=$3
}

# Function to unset shared database configuration
unset_shared_db_config() {
    RDS_ENDPOINT=&quot;&quot;
    DATABASE_USER=&quot;&quot;
    DATABASE_PASSWORD=&quot;&quot;
}

# grant_user_permissions &quot;database_name&quot; &quot;user_name&quot; &quot;user_host&quot;
grant_user_permissions() {
  local database_name=&quot;$1&quot;
  local user_name=&quot;$2&quot;

  # SQL command to grant permissions
  local grant_sql=&quot;GRANT SELECT, INSERT, UPDATE, DELETE ON ${database_name}.* TO &apos;${user_name}&apos;@&apos;%&apos;;&quot;

  # Execute the SQL command using Docker and MySQL client
  docker run --rm $MYSQL_IMAGE mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; \
    -e &quot;$grant_sql&quot; &quot;mysql&quot;

  # Apply the changes
  docker run --rm $MYSQL_IMAGE mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; \
    -e &quot;FLUSH PRIVILEGES;&quot; &quot;mysql&quot;
}

# Flyway cannot create databases. Check if a database exists and create it if not
create_database_if_not_exists() {
  # Parameters: $1 = DATABASE_NAME

  # Use printf to properly quote the password and the entire command
  CMD=$(printf &quot;mysql -h%s -u%s -p&apos;%s&apos; -e &apos;CREATE DATABASE IF NOT EXISTS %s;&apos;&quot; &quot;$RDS_ENDPOINT&quot; &quot;$DATABASE_USER&quot; &quot;$DATABASE_PASSWORD&quot; &quot;$1&quot;)

  # Run the command in a Docker container
  docker run --rm $MYSQL_IMAGE /bin/bash -c &quot;$CMD&quot;
}

drop_all_tables() {
  # Parameters: $1 = DATABASE_NAME

  # Command to disable foreign key checks and fetch list of tables
  FETCH_TABLES_CMD=$(printf &quot;mysql -h%s -u%s -p&apos;%s&apos; --database=%s -Nse &apos;SET FOREIGN_KEY_CHECKS = 0; SHOW TABLES;&apos;&quot; &quot;$RDS_ENDPOINT&quot; &quot;$DATABASE_USER&quot; &quot;$DATABASE_PASSWORD&quot; &quot;$1&quot;)

  # Run the command in a Docker container to fetch the list of tables
  TABLES=$(docker run --rm -e MYSQL_PWD=$DATABASE_PASSWORD $MYSQL_IMAGE mysql -h$RDS_ENDPOINT -u$DATABASE_USER --database=$1 -Nse &quot;SHOW TABLES;&quot;)

  # Iterate over each table and generate the DROP TABLE command
  for TABLE in $TABLES; do
  	echo &quot;Dropping Table: $TABLE&quot;
    DROP_CMD=&quot;SET FOREIGN_KEY_CHECKS = 0; DROP TABLE IF EXISTS $TABLE; SET FOREIGN_KEY_CHECKS = 1;&quot;
    docker run --rm -e MYSQL_PWD=$DATABASE_PASSWORD $MYSQL_IMAGE mysql -h$RDS_ENDPOINT -u$DATABASE_USER --database=$1 -e &quot;$DROP_CMD&quot;
  done
}

# create_top_admin &quot;email&quot; &quot;connection_id&quot;
create_top_admin() {
  docker run --rm $MYSQL_IMAGE mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; \
  -e &quot;CALL CreateSuperUser(&apos;$1&apos;, &apos;$2&apos;);&quot; &quot;auth&quot;
}

does_user_exists() {
	# $1 email
    # $2 connection_id

    local query_result=$(docker run --rm $MYSQL_IMAGE mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; \
    -s -r -e &quot;select email from user where email = &apos;$1&apos; and connectionId = (select uuid from connection where id = &apos;$2&apos;);&quot; &quot;auth&quot;)

    echo &quot;$query_result&quot;
}

# update_token_by_uuid &quot;uuid&quot; &quot;new_token&quot;
update_token_by_uuid() {
  local uuid=&quot;$1&quot;
  local new_token=&quot;$2&quot;

  # Perform the update operation
  docker run --rm $MYSQL_IMAGE mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; \
    -e &quot;UPDATE application SET token=&apos;$new_token&apos; WHERE uuid=UNHEX(&apos;$uuid&apos;);&quot; &quot;auth&quot;
}

# get_token_by_uuid &quot;uuid&quot;
get_token_by_uuid() {
  local uuid=&quot;$1&quot;

  # Query to get the token by UUID
  local query=&quot;SELECT token FROM application WHERE uuid=UNHEX(REPLACE(&apos;$uuid&apos;, &apos;-&apos;, &apos;&apos;));&quot;

  # Execute the query using Docker and MySQL client
  local token=$(docker run --rm $MYSQL_IMAGE mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; \
    -sse &quot;$query&quot; &quot;auth&quot;)

  echo &quot;$token&quot;
}

# run_sql_script &quot;/path/to/your/sql_script.sql&quot; &quot;database_name&quot;
run_sql_script() {
  # Parameters:
  # $1 = PATH_TO_SQL_SCRIPT
  # $2 = DATABASE_NAME

  # Ensure the SQL script file exists
  if [ ! -f &quot;$1&quot; ]; then
    echo &quot;SQL script file does not exist: $1&quot;
    return 1
  fi

  # Run the SQL script in a Docker container
  docker run --rm -v &quot;$1:/sql_script.sql&quot; $MYSQL_IMAGE \
    mysql -h&quot;$RDS_ENDPOINT&quot; -u&quot;$DATABASE_USER&quot; -p&quot;$DATABASE_PASSWORD&quot; &quot;$2&quot; &lt; /sql_script.sql
}
EOF</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
    <hudson.tasks.Shell>
      <command>cat &lt;&lt;&apos;EOF&apos; &gt; string_util_functions.sh
# Function to convert a comma-separated list of domains into a regex pattern
# Will produce ^https?://(www\.)?(www\.domain1\.com|www\.domain2\.com|www\.domain3\.org)
generate_domain_regex() {
  local IFS=&apos;,&apos; # Set the internal field separator to comma
  read -ra ADDR &lt;&lt;&lt; &quot;$1&quot; # Read the list into an array
  local regex=&quot;^https?://(www\.)?(&quot;

  # Loop through the array and append each domain to the regex pattern
  for domain in &quot;${ADDR[@]}&quot;; do
    regex+=&quot;${domain//./\\.}|&quot;
  done

  # Remove the last &apos;|&apos; and close the pattern, allowing for any paths
  regex=&quot;${regex%|}).*&quot;
  echo &quot;${regex}&quot;
}

replace_xml_special_chars() {
    local input_string=&quot;$1&quot;
    local output_string=&quot;&quot;

    # Length of the input string
    local len=${#input_string}
    local i char ord

    for ((i=0; i&lt;len; i++)); do
        char=&quot;${input_string:i:1}&quot;
        case &quot;$char&quot; in
            &apos;&amp;&apos;)
                output_string+=&quot;&amp;amp;&quot;
                ;;
            &apos;&lt;&apos;)
                output_string+=&quot;&amp;lt;&quot;
                ;;
            &apos;&gt;&apos;)
                output_string+=&quot;&amp;gt;&quot;
                ;;
            &apos;&quot;&apos;)
                output_string+=&quot;&amp;quot;&quot;
                ;;
            &quot;&apos;&quot;)
                output_string+=&quot;&amp;apos;&quot;
                ;;
            &apos;?&apos;)
                output_string+=&quot;&amp;#63;&quot;
                ;;
            &apos;#&apos;)
                output_string+=&quot;&amp;#35;&quot;
                ;;
            &apos;{&apos;)
                output_string+=&quot;&amp;#123;&quot;
                ;;
            *)
                output_string+=&quot;$char&quot;
                ;;
        esac
    done

    echo &quot;$output_string&quot;
}
EOF</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers>
    <hudson.tasks.ArtifactArchiver>
      <artifacts>target_group_attachment_functions.sh, role_functions.sh, pic_sure_rds_snapshot.sh, jwt_token.sh, database_migration_functions.sh, secret_functions.sh, database_functions.sh</artifacts>
      <allowEmptyArchive>false</allowEmptyArchive>
      <onlyIfSuccessful>false</onlyIfSuccessful>
      <fingerprint>false</fingerprint>
      <defaultExcludes>true</defaultExcludes>
      <caseSensitive>true</caseSensitive>
      <followSymlinks>false</followSymlinks>
    </hudson.tasks.ArtifactArchiver>
  </publishers>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.45">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>