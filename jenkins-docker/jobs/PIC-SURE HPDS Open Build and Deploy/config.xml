<?xml version='1.1' encoding='UTF-8'?>
<flow-definition plugin="workflow-job@1540.v295eccc9778f">
  <actions>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobAction plugin="pipeline-model-definition@2.2258.v4e96d2b_da_f9b_"/>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction plugin="pipeline-model-definition@2.2258.v4e96d2b_da_f9b_">
      <jobProperties/>
      <triggers/>
      <parameters>
        <string>DESTIGMATIZED_DATASET_S3_OBJECT_KEY</string>
        <string>TARGET_STACK</string>
        <string>STACK_S3_BUCKET</string>
        <string>GIT_HASH</string>
      </parameters>
      <options/>
    </org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction>
  </actions>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.plugins.copyartifact.CopyArtifactPermissionProperty plugin="copyartifact@770.va_6c69e063442">
      <projectNameList>
        <string>*</string>
      </projectNameList>
    </hudson.plugins.copyartifact.CopyArtifactPermissionProperty>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.ChoiceParameterDefinition>
          <name>TARGET_STACK</name>
          <description>Based on selection we determine if is a or b stack.</description>
          <choices class="java.util.Arrays$ArrayList">
            <a class="string-array">
              <string>staging</string>
              <string>live</string>
            </a>
          </choices>
        </hudson.model.ChoiceParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>GIT_HASH</name>
          <description>If you want to a specific GIT_HASH. Leave blank to use the release control</description>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>STACK_S3_BUCKET</name>
          <description>If you want to a specific GIT_HASH. Leave blank to use the release control</description>
          <defaultValue>${stack_s3_bucket}</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>DESTIGMATIZED_DATASET_S3_OBJECT_KEY</name>
          <description>Optional. Setting this value will update related files, folders, datasets, etc.</description>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <definition class="org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition" plugin="workflow-cps@4175.ve65b_fa_663eed">
    <script>import groovy.json.JsonSlurper;
def bdc_ui_docker_tag;

def retrieveBuildSpecId;
def bdcUIBuildSpecId;
def overrideUiBuildSpec;
def pipelineBuildId;
def build_hashes = {};
def hasOverrideUI;
def infrastructure_git_hash;
def targetStack;

pipeline {
    agent any

    parameters {
        choice(name: &apos;TARGET_STACK&apos;, choices: [&apos;staging&apos;,&apos;live&apos;], description: &apos;Based on selection we determine if is a or b stack.&apos;)
        string(name: &apos;GIT_HASH&apos;, defaultValue: &apos;&apos;, description: &apos;If you want to a specific GIT_HASH. Leave blank to use the release control&apos;)
        string(name: &apos;STACK_S3_BUCKET&apos;, defaultValue: &apos;${stack_s3_bucket}&apos;, description: &apos;If you want to a specific GIT_HASH. Leave blank to use the release control&apos;)
        string(name: &apos;DESTIGMATIZED_DATASET_S3_OBJECT_KEY&apos;, defaultValue: &apos;&apos;, description: &apos;Optional. Setting this value will update related files, folders, datasets, etc.&apos;)
    }

    environment {
        SOURCE_SCRIPTS_FOLDER = &quot;${JENKINS_HOME}/workspace/Bash_Functions/&quot;
    }

    stages {
        stage(&apos;Retrieve Stack&apos;) {
            steps {
                script {
                    targetStack = sh(script: &quot;&quot;&quot;
                    bash -c &apos;
                    set +x

                    if [ ! -d &quot;$SOURCE_SCRIPTS_FOLDER&quot; ]; then
                        echo &quot;Error: Source folder does not exist: $SOURCE_SCRIPTS_FOLDER&quot;
                        exit 1
                    fi

                    for script_file in &quot;$SOURCE_SCRIPTS_FOLDER&quot;*.sh; do
                        chmod +x &quot;\$script_file&quot;
                        if [ -f &quot;\$script_file&quot; ] &amp;&amp; [ -x &quot;\$script_file&quot; ]; then
                            . &quot;\$script_file&quot;  # Use dot (.) instead of `source`
                        fi
                    done

                    # The PIC-SURE Pipeline is always used to deploy to staging.
                    get_stack \&quot;${TARGET_STACK}\&quot;
                    &apos;
                    &quot;&quot;&quot;, returnStdout: true).trim()

                    println &quot;TARGET_STACK: $targetStack&quot;
                }
            }
        }
        stage(&apos;Retrieve Build Spec&apos;) {
            when {
                    expression { return params.GIT_HASH == &apos;&apos; }
                }
            steps {
                script {
                    def result = build job: &apos;Retrieve Build Spec&apos;
                    retrieveBuildSpecId = result.number
                }
                script {
                    copyArtifacts filter: &apos;*&apos;, projectName: &apos;Retrieve Build Spec&apos;, selector: specific(&quot;&quot;+retrieveBuildSpecId)
                    sh &apos;cat build-spec.json&apos;
                    sh &apos;cat pipeline_git_commit.txt&apos;
                    sh &apos;pwd&apos;
                    def buildSpec = new JsonSlurper().parse(new File(&apos;/var/jenkins_home/workspace/PIC-SURE HPDS Open Build and Deploy/build-spec.json&apos;))
                    pipelineBuildId = new File(&apos;/var/jenkins_home/workspace/PIC-SURE HPDS Open Build and Deploy/pipeline_git_commit.txt&apos;).text.trim()
                    for(def build : buildSpec.application){
                        build_hashes[build.project_job_git_key] = build.git_hash
                    }
                    infrastructure_git_hash = buildSpec.infrastructure_git_hash
                }
            }
        }
        stage(&apos;PIC-SURE HPDS Build&apos;) {
            steps {
                script {
                    def gitHash = GIT_HASH ? GIT_HASH : build_hashes[&apos;PSF&apos;]
                    def result = build job: &apos;PIC-SURE HPDS Build&apos;,
                        parameters: [
                            [$class: &apos;StringParameterValue&apos;, name: &apos;TARGET_STACK&apos;, value: targetStack],
                            [$class: &apos;StringParameterValue&apos;, name: &apos;GIT_HASH&apos;, value: gitHash]
                        ]
                }
            }
        }
        stage(&apos;PIC-SURE HPDS Open Deploy&apos;) {
            steps {
                script {
                    def result = build job: &apos;PIC-SURE HPDS Open Deploy&apos;, parameters: [
                        [$class: &apos;StringParameterValue&apos;, name: &apos;TARGET_STACK&apos;, value: targetStack],
                        [$class: &apos;StringParameterValue&apos;, name: &apos;STACK_S3_BUCKET&apos;, value: STACK_S3_BUCKET],
                        [$class: &apos;StringParameterValue&apos;, name: &apos;DESTIGMATIZED_DATASET_S3_OBJECT_KEY&apos;, value: DESTIGMATIZED_DATASET_S3_OBJECT_KEY]
                    ]
                }
            }
        }
    }
}</script>
    <sandbox>true</sandbox>
  </definition>
  <triggers/>
  <disabled>false</disabled>
</flow-definition>