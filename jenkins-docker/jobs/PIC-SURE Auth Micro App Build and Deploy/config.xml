<?xml version='1.1' encoding='UTF-8'?>
<flow-definition plugin="workflow-job@1385.vb_58b_86ea_fff1">
  <actions>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobAction plugin="pipeline-model-definition@2.2205.vc9522a_9d5711"/>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction plugin="pipeline-model-definition@2.2205.vc9522a_9d5711">
      <jobProperties/>
      <triggers/>
      <parameters>
        <string>DROP_AUTH_TABLES</string>
        <choice>TARGET_STACK</choice>
        <string>DROP_PICSURE_TABLES</string>
        <string>RUN_DATABASE_MIGRATIONS</string>
        <string>BRANCH</string>
        <string>DATASET_S3_OBJECT_KEY</string>
        <bool>ENABLE_DEBUG</bool>
        <string>SPRING_PROFILE</string>
      </parameters>
      <options/>
    </org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction>
  </actions>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.plugins.copyartifact.CopyArtifactPermissionProperty plugin="copyartifact@749.vfb_dca_a_9b_6549">
      <projectNameList>
        <string>*</string>
      </projectNameList>
    </hudson.plugins.copyartifact.CopyArtifactPermissionProperty>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.ChoiceParameterDefinition>
            <name>TARGET_STACK</name>
            <description>Based on selection we determine if it is the a or b stack.</description>
            <choices class="java.util.Arrays$ArrayList">
                <a class="string-array">
                    <string>staging</string>
                    <string>live</string>
                </a>
            </choices>
        </hudson.model.ChoiceParameterDefinition>
        <hudson.model.StringParameterDefinition>
            <name>BRANCH</name>
            <description>The branch you want to deploy. Leave blank to use the build-spec.</description>
            <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
            <name>DATASET_S3_OBJECT_KEY</name>
            <description>Optional. If provided this will update the fence_mapping.json</description>
            <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
            <name>ENABLE_DEBUG</name>
            <description>Optional. If provided this will update the fence_mapping.json</description>
            <trim>false</trim>
        </hudson.model.BooleanParameterDefinition>
        <hudson.model.StringParameterDefinition>
            <name>SPRING_PROFILE</name>
            <description>Optional. Will override the default spring profile for PSAMA.</description>
            <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>RUN_DATABASE_MIGRATIONS</name>
          <description>Run database migrations</description>
          <defaultValue>true</defaultValue>
        </hudson.model.BooleanParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>DROP_AUTH_TABLES</name>
          <description>Drop tables during migration</description>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>DROP_PICSURE_TABLES</name>
          <description>Drop tables during migration</description>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <definition class="org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition" plugin="workflow-cps@3908.vd6b_b_5a_a_54010">
    <script>import groovy.json.JsonSlurper;
def bdc_ui_docker_tag;

def retrieveBuildSpecId;
def bdcUIBuildSpecId;
def overrideUiBuildSpec;
def pipelineBuildId;
def build_hashes = {};
def hasOverrideUI;
def infrastructure_git_hash;
def targetStack;
pipeline {
    agent any
    parameters {
        choice(name: &apos;TARGET_STACK&apos;, choices: ['staging','live'], description: &apos;Based on selection we determine if is a or b stack.&apos;)
        string(name: &apos;BRANCH&apos;, defaultValue: &apos;&apos;, description: Leave empty to use Build Spec&apos;&apos;)
        string(name: &apos;DATASET_S3_OBJECT_KEY&apos;, defaultValue: &apos;&apos;, description: &apos;&apos;)
        string(name: &apos;STACK_S3_BUCKET&apos;, defaultValue: &apos;&apos;, description: &apos;&apos;)
        string(name: &apos;ENABLE_DEBUG&apos;, defaultValue: &apos;false&apos;, description: &apos;Enable to setup remote debugging. Debugging will use port 9000.&apos;)
        booleanParam(name: &apos;RUN_DATABASE_MIGRATIONS&apos;, defaultValue: true, description: &apos;Run database migrations&apos;)
        booleanParam(name: &apos;DROP_AUTH_TABLES&apos;, defaultValue: false, description: &apos;Drop tables during migration&apos;)
        booleanParam(name: &apos;DROP_PICSURE_TABLES&apos;, defaultValue: false, description: &apos;Drop tables during migration&apos;)
    }
    stages {
        stage(&apos;Retrieve Stack&apos;) {
            steps {
                script {
                    targetStack = sh(script: &quot;&quot;&quot;
                    bash -c &apos;
                    set -x

                    if [ ! -d &quot;$SOURCE_SCRIPTS_FOLDER&quot; ]; then
                        echo &quot;Error: Source folder does not exist: $SOURCE_SCRIPTS_FOLDER&quot;
                        exit 1
                    fi

                    ls -la &quot;$SOURCE_SCRIPTS_FOLDER&quot;

                    for script_file in &quot;$SOURCE_SCRIPTS_FOLDER&quot;*.sh; do
                        chmod +x &quot;\$script_file&quot;
                        if [ -f &quot;\$script_file&quot; ] &amp;&amp; [ -x &quot;\$script_file&quot; ]; then
                            echo &quot;Sourcing \$script_file&quot;
                            . &quot;\$script_file&quot;  # Use dot (.) instead of `source`
                        fi
                    done

                    # The PIC-SURE Pipeline is always used to deploy to staging.
                    get_stack \&quot;staging\&quot;
                    &apos;
                    &quot;&quot;&quot;, returnStdout: true).trim()

                    println &quot;TARGET_STACK: $targetStack&quot;
                }
            }
        }
        stage(&apos;Retrieve Build Spec&apos;) {
            steps {
                when {
                    expression { return params.BRANCH == '' }
                }
                script {
                    def result = build job: &apos;Retrieve Build Spec&apos;
                    retrieveBuildSpecId = result.number
                }
                script {
                    copyArtifacts filter: &apos;*&apos;, projectName: &apos;Retrieve Build Spec&apos;, selector: specific(&quot;&quot;+retrieveBuildSpecId)
                    sh &apos;cat build-spec.json&apos;
                    sh &apos;cat pipeline_git_commit.txt&apos;
                    sh &apos;pwd&apos;
                    def buildSpec = new JsonSlurper().parse(new File(&apos;/var/jenkins_home/workspace/PIC-SURE Auth Micro App Build and Deploy/build-spec.json&apos;))
                    pipelineBuildId = new File(&apos;/var/jenkins_home/workspace/PIC-SURE Auth Micro App Build and Deploy/pipeline_git_commit.txt&apos;).text.trim()
                    for(def build : buildSpec.application){
                        build_hashes[build.project_job_git_key] = build.git_hash
                    }
                    infrastructure_git_hash = buildSpec.infrastructure_git_hash
                }
            }
        }
        stage(&apos;PIC-SURE Auth Micro-App Build&apos;) {
            steps {
                script{
                    def gitHash = BRANCH ? BRANCH : build_hashes[&apos;PSAMA&apos;]
                    def result = build job: &apos;PIC-SURE Auth Micro-App Build&apos;, parameters: [[$class: &apos;StringParameterValue&apos;, name: &apos;TARGET_STACK&apos;, value: targetStack],[$class: &apos;StringParameterValue&apos;, name: &apos;BRANCH&apos;, value: gitHash]]
                }
            }
        }
        stage(&apos;Database Migrations&apos;) {
            when {
                expression { return params.RUN_DATABASE_MIGRATIONS }
            }
            steps {
                script {
                    def result = build job: &apos;Database Migrations&apos;, parameters: [[$class: &apos;StringParameterValue&apos;, name: &apos;infrastructure_git_hash&apos;, value: infrastructure_git_hash],
                    [$class: &apos;BooleanParameterValue&apos;, name: &apos;DROP_PICSURE_TABLES&apos;, value: params.DROP_PICSURE_TABLES],[$class: &apos;BooleanParameterValue&apos;, name: &apos;DROP_AUTH_TABLES&apos;, value: params.DROP_AUTH_TABLES]]
                }
            }
        }
        stage(&apos;PIC-SURE Auth Micro App Deploy&apos;) {
            steps {
                script {
                    def result = build job: &apos;PIC-SURE Auth Micro App Deploy&apos;, parameters:
                        [
                            [$class: &apos;StringParameterValue&apos;, name: &apos;TARGET_STACK&apos;, value: targetStack],
                            [$class: &apos;StringParameterValue&apos;, name: &apos;DATASET_S3_OBJECT_KEY&apos;, value: params.DATASET_S3_OBJECT_KEY],
                            [$class: &apos;StringParameterValue&apos;, name: &apos;SPRING_PROFILE&apos;, value: params.SPRING_PROFILE],
                            [$class: &apos;StringParameterValue&apos;, name: &apos;ENABLE_DEBUG&apos;, value: params.ENABLE_DEBUG]
                        ]
                }
            }
        }
    }
}</script>
    <sandbox>true</sandbox>
  </definition>
  <triggers/>
  <disabled>false</disabled>
</flow-definition>