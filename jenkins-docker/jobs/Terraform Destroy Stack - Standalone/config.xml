<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description>This job will destroy a terraform state for the specified stack passed in. &#xd;
</description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>stack_1</name>
          <defaultValue>a</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>stack_2</name>
          <defaultValue>b</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>destroy_green</name>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>destroy_blue</name>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@5.2.1">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>${infrastructure_git_repo}</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>*/master</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="empty-list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash

# Source folder containing the scripts
source_scripts_folder=&quot;${JENKINS_HOME}/workspace/Bash_Functions/&quot;
ls -la &quot;$source_scripts_folder&quot;

# Iterate through the files in the folder and source them
for script_file in &quot;$source_scripts_folder&quot;*.sh; do
    chmod +x &quot;$script_file&quot;
    if [ -f &quot;$script_file&quot; ] &amp;&amp; [ -x &quot;$script_file&quot; ]; then
        echo &quot;sourcing $script_file&quot;
        source &quot;$script_file&quot;
    fi
done
cd app-infrastructure

 Destroy the green stack. 
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${stack_1}/terraform.tfstate terraform.tfstate
terraform init
private_ips_from_state_1=$(terraform show -json terraform.tfstate | jq -r &apos;.values.root_module.resources[] | select(.type == &quot;aws_instance&quot;).values.private_ip&apos;)
echo &quot;private ip for $stack_1: $private_ips_from_state_1&quot; 

echo &quot;checking Stack: $stack_2&quot;
aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${stack_2}/terraform.tfstate terraform.tfstate
terraform init
private_ips_from_state_2=$(terraform show -json terraform.tfstate | jq -r &apos;.values.root_module.resources[] | select(.type == &quot;aws_instance&quot;).values.private_ip&apos;)
echo &quot;private ip for $stack_2: $private_ips_from_state_2&quot; 

# local vars
assume_role
staging_target_group_arn=$(get_target_group_arn_by_name &quot;$staging_tg_name&quot;)
live_target_group_arn=$(get_target_group_arn_by_name &quot;$live_tg_name&quot;)

staging_private_ips=$(aws elbv2 describe-target-health --target-group-arn $staging_target_group_arn --query &apos;TargetHealthDescriptions[*].Target.Id&apos; --output text)
live_private_ips=$(aws elbv2 describe-target-health --target-group-arn $live_target_group_arn --query &apos;TargetHealthDescriptions[*].Target.Id&apos; --output text)
reset_role


if [[ &quot;$destroy_green&quot; == &quot;true&quot; ]]; then
   echo &quot;Destroying green stack&quot;
   assume_role
   targets=$(aws elbv2 describe-target-health --target-group-arn $staging_target_group_arn --query &apos;TargetHealthDescriptions[*].Target.Id&apos; --output text)
   reset_role
   
   echo &quot;green targets: $targets&quot;
   echo &quot;checking Stack: $stack_1&quot;
   
   for private_ip_from_state in $private_ips_from_state_1; do
      if [[ $targets =~ $private_ip_from_state ]]; then       
        echo &quot;Stack $stack_1 - Destroying&quot;
        aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${stack_1}/terraform.tfstate terraform.tfstate
        terraform init
        
        assume_role
        terraform destroy -auto-approve \
         -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
         -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
         -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
         -var=&quot;target_stack=$stack_1&quot; \
         -var=&quot;picsure_rds_snapshot_id=${picsure_rds_snapshot_id}&quot; \
         -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
         -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
         -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
         -var=&quot;env_public_dns_name_staging=${env_public_dns_name_staging}&quot; \
         -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
         -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
         -var=&quot;analytics_id=${analytics_id}&quot; \
         -var=&quot;tag_manager_id=${tag_manager_id}&quot; \
         -var=&quot;env_is_open_access=${env_is_open_access}&quot; \
         -var=&quot;include_auth_hpds=${include_auth_hpds}&quot; \
         -var=&quot;include_open_hpds=${include_open_hpds}&quot; \
         -var=&quot;environment_name=${environment_name}&quot; \
         -var=&quot;env_staging_subdomain=${env_staging_subdomain}&quot; \
         -var=&quot;application_id_for_base_query=${application_id_for_base_query}&quot; \
         -var=&quot;stack_s3_bucket=${stack_s3_bucket}&quot; \
         -var=&quot;idp_provider=${idp_provider}&quot; \
         -var=&quot;env_project=${env_project}&quot; \
         -var=&quot;picsure_token_introspection_token=${picsure_token_introspection_token}&quot; \
         -var=&quot;picsure_client_secret=${picsure_client_secret}&quot; \
         -var=&quot;fence_client_id=${fence_client_id}&quot; \
         -var=&quot;fence_client_secret=${fence_client_secret}&quot; \
         -var=&quot;idp_provider_uri=${idp_provider_uri}&quot; || true        
     
        reset_role
        
        aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${stack_1}/terraform.tfstate
      fi   
   done
   
   echo &quot;checking Stack: $stack_2&quot;
   for private_ip_from_state in $private_ips_from_state_2; do
      if [[ $targets =~ $private_ip_from_state ]]; then
        echo &quot;Stack $stack_2 - Destroying&quot;
        aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${stack_2}/terraform.tfstate terraform.tfstate
        terraform init
        
        assume_role
        terraform destroy -auto-approve \
         -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
         -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
         -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
         -var=&quot;target_stack=$stack_2&quot; \
         -var=&quot;picsure_rds_snapshot_id=${picsure_rds_snapshot_id}&quot; \
         -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
         -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
         -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
         -var=&quot;env_public_dns_name_staging=${env_public_dns_name_staging}&quot; \
         -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
         -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
         -var=&quot;analytics_id=${analytics_id}&quot; \
         -var=&quot;tag_manager_id=${tag_manager_id}&quot; \
         -var=&quot;env_is_open_access=${env_is_open_access}&quot; \
         -var=&quot;include_auth_hpds=${include_auth_hpds}&quot; \
         -var=&quot;include_open_hpds=${include_open_hpds}&quot; \
         -var=&quot;environment_name=${environment_name}&quot; \
         -var=&quot;env_staging_subdomain=${env_staging_subdomain}&quot; \
         -var=&quot;application_id_for_base_query=${application_id_for_base_query}&quot; \
         -var=&quot;stack_s3_bucket=${stack_s3_bucket}&quot; \
         -var=&quot;idp_provider=${idp_provider}&quot; \
         -var=&quot;env_project=${env_project}&quot; \
         -var=&quot;picsure_token_introspection_token=${picsure_token_introspection_token}&quot; \
         -var=&quot;picsure_client_secret=${picsure_client_secret}&quot; \
         -var=&quot;fence_client_id=${fence_client_id}&quot; \
         -var=&quot;fence_client_secret=${fence_client_secret}&quot; \
         -var=&quot;idp_provider_uri=${idp_provider_uri}&quot; || true           
        reset_role
        
        aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${stack_2}/terraform.tfstate
      fi
   done
   reset_role
fi
# Destroy the blue stack.
if [[ &quot;$destroy_blue&quot; == &quot;true&quot; ]]; then
   echo &quot;Destroying blue stack&quot;
   
   assume_role
   targets=$(aws elbv2 describe-target-health --target-group-arn $live_target_group_arn --query &apos;TargetHealthDescriptions[*].Target.Id&apos; --output text)
   reset_role
   
   echo &quot;blue targets: $targets&quot;
   echo &quot;checking Stack: $stack_1&quot;
  
  for private_ip_from_state in $private_ips_from_state_1; do
      if [[ $targets =~ $private_ip_from_state ]]; then
        echo &quot;Stack $stack_1 - Destroying&quot;
        aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${stack_1}/terraform.tfstate terraform.tfstate
        terraform init
        
        assume_role
        terraform destroy -auto-approve \
         -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
         -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
         -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
         -var=&quot;target_stack=$stack_1&quot; \
         -var=&quot;picsure_rds_snapshot_id=${picsure_rds_snapshot_id}&quot; \
         -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
         -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
         -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
         -var=&quot;env_public_dns_name_staging=${env_public_dns_name_staging}&quot; \
         -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
         -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
         -var=&quot;analytics_id=${analytics_id}&quot; \
         -var=&quot;tag_manager_id=${tag_manager_id}&quot; \
         -var=&quot;env_is_open_access=${env_is_open_access}&quot; \
         -var=&quot;include_auth_hpds=${include_auth_hpds}&quot; \
         -var=&quot;include_open_hpds=${include_open_hpds}&quot; \
         -var=&quot;environment_name=${environment_name}&quot; \
         -var=&quot;env_staging_subdomain=${env_staging_subdomain}&quot; \
         -var=&quot;application_id_for_base_query=${application_id_for_base_query}&quot; \
         -var=&quot;stack_s3_bucket=${stack_s3_bucket}&quot; \
         -var=&quot;idp_provider=${idp_provider}&quot; \
         -var=&quot;env_project=${env_project}&quot; \
         -var=&quot;picsure_token_introspection_token=${picsure_token_introspection_token}&quot; \
         -var=&quot;picsure_client_secret=${picsure_client_secret}&quot; \
         -var=&quot;fence_client_id=${fence_client_id}&quot; \
         -var=&quot;fence_client_secret=${fence_client_secret}&quot; \
         -var=&quot;idp_provider_uri=${idp_provider_uri}&quot; || true   
         reset_role
        
        aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${stack_1}/terraform.tfstate
      fi
   done
   
   echo &quot;checking Stack: $stack_2&quot;
   for private_ip_from_state in $private_ips_from_state_2; do
      if [[ $targets =~ $private_ip_from_state ]]; then
        echo &quot;Stack $stack_2 - Destroying&quot;
        aws s3 cp s3://$stack_s3_bucket/deployment_state_metadata/${stack_2}/terraform.tfstate terraform.tfstate
        terraform init
        
        assume_role
        terraform destroy -auto-approve \
         -var=&quot;dataset_s3_object_key=${dataset_s3_object_key}&quot;  \
         -var=&quot;destigmatized_dataset_s3_object_key=${destigmatized_dataset_s3_object_key}&quot;  \
         -var=&quot;genomic_dataset_s3_object_key=${genomic_dataset_s3_object_key}&quot; \
         -var=&quot;target_stack=$stack_2&quot; \
         -var=&quot;picsure_rds_snapshot_id=${picsure_rds_snapshot_id}&quot; \
         -var=&quot;stack_githash=`echo ${deployment_git_hash} |cut -c1-7`&quot; \
         -var=&quot;stack_githash_long=${deployment_git_hash}&quot; \
         -var=&quot;env_public_dns_name=${env_public_dns_name}&quot; \
         -var=&quot;env_public_dns_name_staging=${env_public_dns_name_staging}&quot; \
         -var=&quot;env_private_dns_name=${env_private_dns_name}&quot; \
         -var=&quot;env_hosted_zone_id=${env_hosted_zone_id}&quot; \
         -var=&quot;analytics_id=${analytics_id}&quot; \
         -var=&quot;tag_manager_id=${tag_manager_id}&quot; \
         -var=&quot;env_is_open_access=${env_is_open_access}&quot; \
         -var=&quot;include_auth_hpds=${include_auth_hpds}&quot; \
         -var=&quot;include_open_hpds=${include_open_hpds}&quot; \
         -var=&quot;environment_name=${environment_name}&quot; \
         -var=&quot;env_staging_subdomain=${env_staging_subdomain}&quot; \
         -var=&quot;application_id_for_base_query=${application_id_for_base_query}&quot; \
         -var=&quot;stack_s3_bucket=${stack_s3_bucket}&quot; \
         -var=&quot;idp_provider=${idp_provider}&quot; \
         -var=&quot;env_project=${env_project}&quot; \
         -var=&quot;picsure_token_introspection_token=${picsure_token_introspection_token}&quot; \
         -var=&quot;picsure_client_secret=${picsure_client_secret}&quot; \
         -var=&quot;fence_client_id=${fence_client_id}&quot; \
         -var=&quot;fence_client_secret=${fence_client_secret}&quot; \
         -var=&quot;idp_provider_uri=${idp_provider_uri}&quot; || true   
         reset_role
        
        aws s3 cp terraform.tfstate s3://$stack_s3_bucket/deployment_state_metadata/${stack_2}/terraform.tfstate
      fi
   done
   reset_role
fi
</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.45">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>